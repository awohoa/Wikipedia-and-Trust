# Trust in Wikipedia

## Group Members
1. Rhea John
2. Imara Zepeda
3. Julia Nguyen
4. AB Owusu-Agyemang
5. Julian Ting
6. Jack Flanagan

## Abstract
In the new world of AI and technology, many wonder how reliable internet sources are. This includes one of the most popular sources of information, Wikipedia. Wikipedia remains relevant and trustworthy partly because it relies on humans who add content by posting and editing contributions on talk pages. However, AI may weaken this reliance on Wikipedia, as large language models can pull answers from Wikipedia and other sources so quickly that users have less need to engage and interact on Wikipedia pages. Our project explores how Wikipedia sustains its trust and relevance in the age of AI, and what its role may look like in the coming years.

## Research Questions
1. How does Wikipedia sustain trust in its content despite being open for anyone to edit?
Features like citations, page protection, and talk pages all help. Unlike AI tools, Wikipedia makes the editing process visible—users can see who contributed, when changes happened, and why.

2. In what ways does Wikipedia still have advantages over AI-generated content?
Transparency: users can check edit histories, see talk page debates, and review citations.
Accountability: edits are often tied to specific contributors.
These features give Wikipedia a level of credibility that AI doesn't because wikipedia articles have citations and discussion which AI doesn't have or often times their citations or links are broken/incorrect.

3. How might Wikipedia adapt in the AI era to remain sustainable and trustworthy?
It could use AI as a tool—for example, to help flag unreliable sources or suggest citations. At the same time, it could highlight its human-centered editing model, showing how real people debate, collaborate, and verify information.

4. Why are human contributors still so important for Wikipedia?
Without regular users checking and updating content, Wikipedia could lose accuracy and relevance. The platform might need new strategies (like recognition programs or partnerships with schools) to keep people motivated to contribute.


## Methodology
1. We will design a short survey for our classmates (who actively post on Wikipedia) to ask whether and how they use AI tools when writing or editing content. The survey will also ask about perceptions of Wikipedia’s trustworthiness compared to AI tools. This will provide insight into how contributors themselves see the role of AI in the editing process.
   
2. We will ask Chatgpt questions about the same topics as the selected Wikipedia articles of our choice. We will then compare LLM responses with Wikipedia’s current content to examine overlap, accuracy, and differences.

3. Finally, we will compare our findings with prior research on Wikipedia governance, online trust, and AI’s impact on collaborative knowledge production.


## The Prototype Discription 
The prototype finds a random wikipedia article and returns its name, the amount of sources it has, and the amount of revivsions it had.
