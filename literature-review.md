# Research Articles 


1. **Implications of generative AI for knowledge integrity on Wikipedia**
Ford, Heather; Davis Michael (2024). ["Implications of generative AI for knowledge integrity on Wikipedia"](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Implications+of+generative+AI+for+knowledge+integrity+on+Wikipedia&btnG=) | [pdf](https://wikiworkshop.org/2025/paper/wikiworkshop_2025_paper_54.pdf) 

3. **Will large language models diminish the reliance on Wikipedia?**
Wagner, Christian; Jiang, Lin (2025) ["Death by AI: Will large language models diminish Wikipedia?"](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Death+by+AI%3A+Will+large+language+models+diminish+Wikipedia%3F&btnG=) | [pdf](https://asistdl.onlinelibrary.wiley.com/doi/epdf/10.1002/asi.24975) 


5. **Artificial Intelligence, Trust, and Relevance of Online Knowledge**
   
Vetter, Matthew A.; Jiang, Jialei; McDowell, Zachary J. (2025).
["An endangered species: how LLMs threaten Wikipedia’s sustainability."](https://link.springer.com/article/10.1007/s00146-025-02199-9)
[Google Scholar](https://scholar.google.com/scholar_lookup?title=An+endangered+species:+how+LLMs+threaten+Wikipedia%E2%80%99s+sustainability&author=Vetter&author=Jiang&author=McDowell&publication_year=2025) | [pdf](https://link.springer.com/content/pdf/10.1007/s00146-025-02199-9.pdf)  

This article connects to our main question because it addresses both trust and relevance. The authors point out that AI systems often pull from Wikipedia without giving much credit, which raises the question about whether people can really trust how that information is being used. The article also talks about sustainability. If people stop going to Wikipedia and just use AI instead, fewer people will contribute and the platform could lose what makes it special as a community-driven project. What’s especially helpful about this article is that it doesn’t just focus on problems happening right now, it also warns about what could happen in the future and suggests ways to keep Wikipedia both trustworthy and relevant.

4. **Perceived Trustworthiness of Wikipedia Pages**

Areia, Carlos; Burton, Kath; Taylor, Mike; Watkinson, Charles. (2025).
["Research citations building trust in Wikipedia: Results from a survey of published authors."](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0320334)
[Google Scholar](https://scholar.google.com/scholar_lookup?title=Research+citations+building+trust+in+Wikipedia:+Results+from+a+survey+of+published+authors&author=Areia&author=Burton&author=Taylor&author=Watkinson&publication_year=2025) | [pdf](https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0320334&type=printable)  

This article examines how researchers perceive the trustworthiness of Wikipedia citations and how the platform represents their work. Using a large survey of over 700 published authors whose work had been cited on Wikipedia, the study explored sentiment towards Wikipedia as a source of reliable information. The findings show that authors generally view research citations on Wikipedia positively, especially when proper engagement practices are followed. It also highlights differences in trust depending on publication type (articles vs. books) and academic discipline (Humanities and Social Sciences vs. STEM). This is relevant to our project because it demonstrates that trustworthiness on Wikipedia is influenced by specific page properties, such as the quality and representation of citations, and suggests that user perception plays a key role in maintaining Wikipedia’s credibility.
